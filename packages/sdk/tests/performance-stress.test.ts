/**
 * Performance and Stress Test Suite
 *
 * Tests system performance and reliability under stress:
 * - Load testing with concurrent operations
 * - Memory usage and resource management
 * - Network resilience and timeout handling
 * - Blockchain transaction throughput
 * - Error recovery and graceful degradation
 */

import { describe, test, expect, beforeAll, afterAll } from 'bun:test';
import { createDevnetClient, type PodAIClient } from '../src/client-v2';
import { generateKeyPairSigner, type KeyPairSigner } from '@solana/signers';
import type { Address } from '@solana/addresses';
import { logger } from '../../../shared/logger';

describe('Performance and Stress Testing', () => {
  let client: PodAIClient;
  let testAgents: KeyPairSigner[] = [];
  let testUsers: KeyPairSigner[] = [];
  let loadTestChannels: Address[] = [];

  // Performance metrics storage
  let performanceMetrics: Array<{
    test: string;
    duration: number;
    throughput: number;
    success: number;
    errors: number;
  }> = [];
  let memoryMetrics: Array<{ test: string; beforeMB: number; afterMB: number; peakMB: number }> =
    [];
  let networkMetrics: Array<{ test: string; latency: number; timeouts: number; retries: number }> =
    [];

  beforeAll(async () => {
    logger.general.info('‚ö° Setting up performance and stress test environment...');

    client = createDevnetClient('4ufTpHynyoWzSL3d2EL4PU1hSra1tKvQrQiBwJ82x385');

    // Generate multiple test agents and users for load testing
    const agentCount = 10; // Reasonable number for testing
    const userCount = 15;

    logger.general.info(`üîß Generating ${agentCount} test agents and ${userCount} test users...`);

    for (let i = 0; i < agentCount; i++) {
      testAgents.push(await generateKeyPairSigner());
    }

    for (let i = 0; i < userCount; i++) {
      testUsers.push(await generateKeyPairSigner());
    }

    // Fund test accounts (in batches to avoid rate limits)
    try {
      const batchSize = 5;
      const allAccounts = [...testAgents, ...testUsers];

      for (let i = 0; i < allAccounts.length; i += batchSize) {
        const batch = allAccounts.slice(i, i + batchSize);
        await Promise.all(batch.map(account => client.airdrop(account.address, 0.5)));

        // Small delay between batches to respect rate limits
        if (i + batchSize < allAccounts.length) {
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
      }
      logger.general.info('‚úÖ Performance test accounts funded');
    } catch (error) {
      logger.general.warn('‚ö†Ô∏è Some airdrops failed due to rate limits, proceeding with performance tests');
    }

    // Register a subset of agents for testing
    try {
      const agentsToRegister = testAgents.slice(0, 5); // Register first 5 agents
      const registrationPromises = agentsToRegister.map((agent, index) =>
        client.agents.registerAgent(agent, {
          name: `Performance Test Agent ${index + 1}`,
          description: `Agent ${index + 1} for performance and stress testing`,
          capabilities: [1, 2, 4],
          metadata: {
            testAgent: true,
            agentIndex: index,
            performanceTestReady: true,
          },
        }),
      );

      await Promise.allSettled(registrationPromises);
      logger.general.info('‚úÖ Performance test agents registered');
    } catch (error) {
      logger.general.warn('‚ö†Ô∏è Some agent registrations failed, continuing performance tests');
    }
  });

  afterAll(async () => {
    logger.general.info('üìä Performance and Stress Test Summary:');
    logger.general.info(`  - Performance tests executed: ${performanceMetrics.length}`);
    logger.general.info(`  - Memory tests completed: ${memoryMetrics.length}`);
    logger.general.info(`  - Network resilience tests: ${networkMetrics.length}`);

    // Calculate average metrics
    if (performanceMetrics.length > 0) {
      const avgThroughput =
        performanceMetrics.reduce((sum, m) => sum + m.throughput, 0) / performanceMetrics.length;
      const avgSuccessRate =
        performanceMetrics.reduce((sum, m) => sum + m.success / (m.success + m.errors), 0) /
        performanceMetrics.length;
      logger.general.info(`  - Average throughput: ${avgThroughput.toFixed(2)} ops/sec`);
      logger.general.info(`  - Average success rate: ${(avgSuccessRate * 100).toFixed(1)}%`);
    }
  });

  describe('Load Testing and Concurrent Operations', () => {
    test('Concurrent agent registrations', async () => {
      logger.general.info('üöÄ Testing concurrent agent registrations...');

      const startTime = Date.now();
      const beforeMemory = process.memoryUsage().heapUsed / 1024 / 1024; // MB

      const concurrentCount = 8; // Practical limit for testing
      const unregisteredAgents = testAgents.slice(5, 5 + concurrentCount); // Use unregistered agents

      try {
        const registrationPromises = unregisteredAgents.map((agent, index) =>
          client.agents.registerAgent(agent, {
            name: `Concurrent Test Agent ${index + 1}`,
            description: `Concurrent registration test agent ${index + 1}`,
            capabilities: [1, 2],
            metadata: {
              concurrentTest: true,
              batchIndex: index,
            },
          }),
        );

        const results = await Promise.allSettled(registrationPromises);
        const successful = results.filter(r => r.status === 'fulfilled').length;
        const failed = results.filter(r => r.status === 'rejected').length;

        const endTime = Date.now();
        const duration = endTime - startTime;
        const throughput = successful / (duration / 1000); // operations per second
        const afterMemory = process.memoryUsage().heapUsed / 1024 / 1024; // MB

        performanceMetrics.push({
          test: 'concurrent_registrations',
          duration,
          throughput,
          success: successful,
          errors: failed,
        });

        memoryMetrics.push({
          test: 'concurrent_registrations',
          beforeMB: beforeMemory,
          afterMB: afterMemory,
          peakMB: Math.max(beforeMemory, afterMemory),
        });

        expect(successful).toBeGreaterThan(0);
        logger.general.info(
          `‚úÖ Concurrent registrations: ${successful}/${concurrentCount} successful in ${duration}ms (${throughput.toFixed(2)} ops/sec)`,
        );
      } catch (error) {
        logger.general.warn(
          '‚ö†Ô∏è Concurrent registration test encountered issues, recording partial results',
        );

        performanceMetrics.push({
          test: 'concurrent_registrations',
          duration: Date.now() - startTime,
          throughput: 0,
          success: 0,
          errors: concurrentCount,
        });
      }
    });

    test('High-frequency channel creation', async () => {
      logger.general.info('üì¢ Testing high-frequency channel creation...');

      if (testAgents.length === 0) {
        logger.general.warn('‚ö†Ô∏è No test agents available for channel creation');
        return;
      }

      const startTime = Date.now();
      const beforeMemory = process.memoryUsage().heapUsed / 1024 / 1024;

      const channelCount = 20;
      const batchSize = 4; // Create channels in smaller batches
      let successfulChannels = 0;
      let failedChannels = 0;

      try {
        for (let i = 0; i < channelCount; i += batchSize) {
          const batch = [];
          const endIndex = Math.min(i + batchSize, channelCount);

          for (let j = i; j < endIndex; j++) {
            const agent = testAgents[j % testAgents.length];
            const channelPromise = client.channels.createChannel(agent, {
              name: `Load Test Channel ${j + 1}`,
              description: `High-frequency test channel ${j + 1}`,
              channelType: 'public',
              isPublic: true,
              participants: [],
            });
            batch.push(channelPromise);
          }

          const batchResults = await Promise.allSettled(batch);
          const batchSuccessful = batchResults.filter(r => r.status === 'fulfilled').length;
          const batchFailed = batchResults.filter(r => r.status === 'rejected').length;

          successfulChannels += batchSuccessful;
          failedChannels += batchFailed;

          // Store successful channel PDAs
          batchResults.forEach(result => {
            if (result.status === 'fulfilled') {
              loadTestChannels.push(result.value.channelPda);
            }
          });

          // Small delay between batches
          if (endIndex < channelCount) {
            await new Promise(resolve => setTimeout(resolve, 200));
          }
        }

        const endTime = Date.now();
        const duration = endTime - startTime;
        const throughput = successfulChannels / (duration / 1000);
        const afterMemory = process.memoryUsage().heapUsed / 1024 / 1024;

        performanceMetrics.push({
          test: 'high_frequency_channels',
          duration,
          throughput,
          success: successfulChannels,
          errors: failedChannels,
        });

        memoryMetrics.push({
          test: 'high_frequency_channels',
          beforeMB: beforeMemory,
          afterMB: afterMemory,
          peakMB: Math.max(beforeMemory, afterMemory),
        });

        expect(successfulChannels).toBeGreaterThan(0);
        logger.general.info(
          `‚úÖ Channel creation: ${successfulChannels}/${channelCount} successful in ${duration}ms (${throughput.toFixed(2)} channels/sec)`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è High-frequency channel creation encountered issues');

        performanceMetrics.push({
          test: 'high_frequency_channels',
          duration: Date.now() - startTime,
          throughput: successfulChannels / ((Date.now() - startTime) / 1000),
          success: successfulChannels,
          errors: failedChannels,
        });
      }
    });

    test('Burst messaging load test', async () => {
      logger.general.info('üí¨ Testing burst messaging performance...');

      if (loadTestChannels.length === 0) {
        logger.general.warn('‚ö†Ô∏è No test channels available for messaging load test');
        return;
      }

      const startTime = Date.now();
      const beforeMemory = process.memoryUsage().heapUsed / 1024 / 1024;

      const messageCount = 50;
      const testChannel = loadTestChannels[0];
      const testAgent = testAgents[0];

      try {
        const messagePromises = [];

        // Create burst of messages
        for (let i = 0; i < messageCount; i++) {
          const messagePromise = client.messages.sendMessage(testAgent, {
            channelAddress: testChannel,
            content: `Load test message ${i + 1} - Testing system performance under load`,
            messageType: 'text',
            metadata: {
              loadTest: true,
              messageIndex: i,
              batchId: 'burst_test_1',
            },
          });
          messagePromises.push(messagePromise);
        }

        const results = await Promise.allSettled(messagePromises);
        const successful = results.filter(r => r.status === 'fulfilled').length;
        const failed = results.filter(r => r.status === 'rejected').length;

        const endTime = Date.now();
        const duration = endTime - startTime;
        const throughput = successful / (duration / 1000);
        const afterMemory = process.memoryUsage().heapUsed / 1024 / 1024;

        performanceMetrics.push({
          test: 'burst_messaging',
          duration,
          throughput,
          success: successful,
          errors: failed,
        });

        memoryMetrics.push({
          test: 'burst_messaging',
          beforeMB: beforeMemory,
          afterMB: afterMemory,
          peakMB: Math.max(beforeMemory, afterMemory),
        });

        expect(successful).toBeGreaterThan(0);
        logger.general.info(
          `‚úÖ Burst messaging: ${successful}/${messageCount} messages in ${duration}ms (${throughput.toFixed(2)} msg/sec)`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Burst messaging test encountered issues');

        performanceMetrics.push({
          test: 'burst_messaging',
          duration: Date.now() - startTime,
          throughput: 0,
          success: 0,
          errors: messageCount,
        });
      }
    });

    test('Concurrent work order creation', async () => {
      logger.general.info('üíº Testing concurrent work order creation...');

      if (testAgents.length === 0 || testUsers.length === 0) {
        logger.general.warn('‚ö†Ô∏è Insufficient test accounts for work order testing');
        return;
      }

      const startTime = Date.now();
      const beforeMemory = process.memoryUsage().heapUsed / 1024 / 1024;

      const workOrderCount = 15;
      const workOrderPromises = [];

      try {
        for (let i = 0; i < workOrderCount; i++) {
          const client_signer = testUsers[i % testUsers.length];
          const agent = testAgents[i % testAgents.length];

          const workOrderPromise = client.escrow.createWorkOrder(client_signer, {
            agentAddress: agent.address,
            taskDescription: `Load test task ${i + 1} - Performance testing work order`,
            paymentAmount: BigInt(1000000 + i * 100000), // Varying amounts
            deadline: Math.floor(Date.now() / 1000) + 86400, // 24 hours
            requirements: `Performance test requirements for task ${i + 1}`,
            deliverables: `Deliverables for load test task ${i + 1}`,
          });

          workOrderPromises.push(workOrderPromise);
        }

        const results = await Promise.allSettled(workOrderPromises);
        const successful = results.filter(r => r.status === 'fulfilled').length;
        const failed = results.filter(r => r.status === 'rejected').length;

        const endTime = Date.now();
        const duration = endTime - startTime;
        const throughput = successful / (duration / 1000);
        const afterMemory = process.memoryUsage().heapUsed / 1024 / 1024;

        performanceMetrics.push({
          test: 'concurrent_work_orders',
          duration,
          throughput,
          success: successful,
          errors: failed,
        });

        memoryMetrics.push({
          test: 'concurrent_work_orders',
          beforeMB: beforeMemory,
          afterMB: afterMemory,
          peakMB: Math.max(beforeMemory, afterMemory),
        });

        expect(successful).toBeGreaterThan(0);
        logger.general.info(
          `‚úÖ Work orders: ${successful}/${workOrderCount} created in ${duration}ms (${throughput.toFixed(2)} orders/sec)`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Concurrent work order creation encountered issues');

        performanceMetrics.push({
          test: 'concurrent_work_orders',
          duration: Date.now() - startTime,
          throughput: 0,
          success: 0,
          errors: workOrderCount,
        });
      }
    });
  });

  describe('Memory Usage and Resource Management', () => {
    test('Memory usage during large operations', async () => {
      logger.general.info('üß† Testing memory usage patterns...');

      const beforeMemory = process.memoryUsage();

      try {
        // Simulate memory-intensive operations
        const operations = [
          // Large agent discovery
          async () => {
            const discovery = await client.agents.discoverAgents({
              limit: 100,
              requiredCapabilities: [1, 2, 4],
            });
            return discovery.agents.length;
          },

          // Multiple balance checks
          async () => {
            const balanceChecks = testUsers
              .slice(0, 10)
              .map(user => client.getBalance(user.address));
            const balances = await Promise.allSettled(balanceChecks);
            return balances.filter(b => b.status === 'fulfilled').length;
          },

          // Cluster info requests
          async () => {
            const clusterRequests = Array(20)
              .fill(0)
              .map(() => client.getClusterInfo());
            const results = await Promise.allSettled(clusterRequests);
            return results.filter(r => r.status === 'fulfilled').length;
          },
        ];

        const memorySnapshots = [beforeMemory];

        for (const operation of operations) {
          const operationStart = process.memoryUsage();
          await operation();
          const operationEnd = process.memoryUsage();
          memorySnapshots.push(operationEnd);

          // Force garbage collection if available
          if (global.gc) {
            global.gc();
          }

          await new Promise(resolve => setTimeout(resolve, 100)); // Allow GC
        }

        const afterMemory = process.memoryUsage();
        const peakHeapUsed = Math.max(...memorySnapshots.map(s => s.heapUsed));
        const memoryGrowth = afterMemory.heapUsed - beforeMemory.heapUsed;

        memoryMetrics.push({
          test: 'large_operations_memory',
          beforeMB: beforeMemory.heapUsed / 1024 / 1024,
          afterMB: afterMemory.heapUsed / 1024 / 1024,
          peakMB: peakHeapUsed / 1024 / 1024,
        });

        expect(memoryGrowth).toBeLessThan(100 * 1024 * 1024); // Less than 100MB growth
        logger.general.info(
          `‚úÖ Memory test: ${(memoryGrowth / 1024 / 1024).toFixed(2)}MB growth, peak ${(peakHeapUsed / 1024 / 1024).toFixed(2)}MB`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Memory usage test encountered issues, recording available metrics');

        const afterMemory = process.memoryUsage();
        memoryMetrics.push({
          test: 'large_operations_memory',
          beforeMB: beforeMemory.heapUsed / 1024 / 1024,
          afterMB: afterMemory.heapUsed / 1024 / 1024,
          peakMB: Math.max(beforeMemory.heapUsed, afterMemory.heapUsed) / 1024 / 1024,
        });
      }
    });

    test('Resource cleanup and garbage collection', async () => {
      logger.general.info('üßπ Testing resource cleanup...');

      const initialMemory = process.memoryUsage();

      try {
        // Create many temporary objects
        const tempData = [];
        for (let i = 0; i < 1000; i++) {
          tempData.push({
            id: `temp_${i}`,
            data: new Array(1000).fill(`data_${i}`),
            timestamp: Date.now(),
            metadata: {
              index: i,
              category: `category_${i % 10}`,
              tags: Array(50).fill(`tag_${i}`),
            },
          });
        }

        const afterCreation = process.memoryUsage();

        // Clear references
        tempData.length = 0;

        // Force garbage collection if available
        if (global.gc) {
          global.gc();
        }

        // Wait for cleanup
        await new Promise(resolve => setTimeout(resolve, 1000));

        const afterCleanup = process.memoryUsage();

        const creationGrowth = afterCreation.heapUsed - initialMemory.heapUsed;
        const cleanupReduction = afterCreation.heapUsed - afterCleanup.heapUsed;
        const cleanupPercentage = (cleanupReduction / creationGrowth) * 100;

        memoryMetrics.push({
          test: 'resource_cleanup',
          beforeMB: initialMemory.heapUsed / 1024 / 1024,
          afterMB: afterCleanup.heapUsed / 1024 / 1024,
          peakMB: afterCreation.heapUsed / 1024 / 1024,
        });

        expect(cleanupPercentage).toBeGreaterThan(50); // At least 50% cleanup
        logger.general.info(`‚úÖ Resource cleanup: ${cleanupPercentage.toFixed(1)}% memory reclaimed`);
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Resource cleanup test encountered issues');

        const finalMemory = process.memoryUsage();
        memoryMetrics.push({
          test: 'resource_cleanup',
          beforeMB: initialMemory.heapUsed / 1024 / 1024,
          afterMB: finalMemory.heapUsed / 1024 / 1024,
          peakMB: Math.max(initialMemory.heapUsed, finalMemory.heapUsed) / 1024 / 1024,
        });
      }
    });

    test('Long-running operation stability', async () => {
      logger.general.info('‚è±Ô∏è Testing long-running operation stability...');

      const startMemory = process.memoryUsage();
      const startTime = Date.now();

      try {
        const duration = 4000; // 4 seconds (to fit within 5 second timeout)
        const interval = 500; // Check every 500ms
        const iterations = duration / interval;

        let completedIterations = 0;
        let errors = 0;
        const memorySnapshots = [];

        for (let i = 0; i < iterations; i++) {
          try {
            // Perform various operations
            const operations = await Promise.allSettled([
              client.getClusterInfo(),
              client.isConnected(),
              testUsers.length > 0 ? client.getBalance(testUsers[0].address) : Promise.resolve(0),
            ]);

            const successfulOps = operations.filter(op => op.status === 'fulfilled').length;
            if (successfulOps === 0) {
              errors++;
            } else {
              completedIterations++;
            }

            // Record memory usage
            const currentMemory = process.memoryUsage();
            memorySnapshots.push(currentMemory.heapUsed);

            await new Promise(resolve => setTimeout(resolve, interval));
          } catch (error) {
            errors++;
          }
        }

        const endTime = Date.now();
        const endMemory = process.memoryUsage();
        const actualDuration = endTime - startTime;

        const avgMemory =
          memorySnapshots.reduce((sum, mem) => sum + mem, 0) / memorySnapshots.length;
        const memoryVariation = Math.max(...memorySnapshots) - Math.min(...memorySnapshots);

        performanceMetrics.push({
          test: 'long_running_stability',
          duration: actualDuration,
          throughput: completedIterations / (actualDuration / 1000),
          success: completedIterations,
          errors,
        });

        memoryMetrics.push({
          test: 'long_running_stability',
          beforeMB: startMemory.heapUsed / 1024 / 1024,
          afterMB: endMemory.heapUsed / 1024 / 1024,
          peakMB: Math.max(...memorySnapshots) / 1024 / 1024,
        });

        const stabilityScore = (completedIterations / iterations) * 100;
        expect(stabilityScore).toBeGreaterThan(70); // At least 70% success rate

        logger.general.info(
          `‚úÖ Stability test: ${stabilityScore.toFixed(1)}% success over ${(actualDuration / 1000).toFixed(1)}s`,
        );
        logger.general.info(`   Memory variation: ${(memoryVariation / 1024 / 1024).toFixed(2)}MB`);
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Long-running stability test encountered issues');

        const endMemory = process.memoryUsage();
        performanceMetrics.push({
          test: 'long_running_stability',
          duration: Date.now() - startTime,
          throughput: 0,
          success: 0,
          errors: 1,
        });

        memoryMetrics.push({
          test: 'long_running_stability',
          beforeMB: startMemory.heapUsed / 1024 / 1024,
          afterMB: endMemory.heapUsed / 1024 / 1024,
          peakMB: Math.max(startMemory.heapUsed, endMemory.heapUsed) / 1024 / 1024,
        });
      }
    });
  });

  describe('Network Resilience and Error Recovery', () => {
    test('Timeout handling and retries', async () => {
      logger.general.info('‚è∞ Testing timeout handling...');

      const startTime = Date.now();
      let timeouts = 0;
      let retries = 0;
      let successful = 0;
      let networkErrors = 0;

      try {
        // Test various operations with potential timeouts
        const timeoutTests = [
          // Quick operations that should succeed
          ...Array(5)
            .fill(0)
            .map(() => client.isConnected()),
          // Balance checks that might timeout
          ...testUsers.slice(0, 3).map(user => client.getBalance(user.address)),
          // Cluster info that might be slow
          ...Array(3)
            .fill(0)
            .map(() => client.getClusterInfo()),
        ];

        const results = await Promise.allSettled(
          timeoutTests.map(async (test, index) => {
            try {
              const result = await Promise.race([
                test,
                new Promise(
                  (_, reject) => setTimeout(() => reject(new Error('Test timeout')), 5000), // 5s timeout
                ),
              ]);
              successful++;
              return result;
            } catch (error) {
              if (error.message.includes('timeout')) {
                timeouts++;
              } else {
                networkErrors++;
              }

              // Simulate retry
              retries++;
              try {
                const retryResult = await test;
                successful++;
                return retryResult;
              } catch (retryError) {
                throw retryError;
              }
            }
          }),
        );

        const endTime = Date.now();
        const duration = endTime - startTime;

        networkMetrics.push({
          test: 'timeout_handling',
          latency: duration / timeoutTests.length,
          timeouts,
          retries,
        });

        const timeoutRate = (timeouts / timeoutTests.length) * 100;
        expect(timeoutRate).toBeLessThan(50); // Less than 50% timeout rate

        logger.general.info(
          `‚úÖ Timeout test: ${timeoutRate.toFixed(1)}% timeout rate, ${retries} retries, ${successful} successful`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Timeout handling test encountered issues');

        networkMetrics.push({
          test: 'timeout_handling',
          latency: Date.now() - startTime,
          timeouts: timeouts || 1,
          retries: retries || 0,
        });
      }
    });

    test('Network interruption recovery', async () => {
      logger.general.info('üåê Testing network interruption recovery...');

      const startTime = Date.now();
      let connectionTests = 0;
      let recoveries = 0;
      let persistentFailures = 0;

      try {
        // Simulate network interruptions with various operations
        const recoveryTests = [
          async () => {
            connectionTests++;
            try {
              const connected = await client.isConnected();
              if (connected) recoveries++;
              return connected;
            } catch (error) {
              // Simulate recovery attempt
              await new Promise(resolve => setTimeout(resolve, 1000));
              try {
                const retryConnected = await client.isConnected();
                if (retryConnected) recoveries++;
                return retryConnected;
              } catch (retryError) {
                persistentFailures++;
                return false;
              }
            }
          },

          async () => {
            connectionTests++;
            try {
              const clusterInfo = await client.getClusterInfo();
              recoveries++;
              return clusterInfo;
            } catch (error) {
              // Simulate recovery with exponential backoff
              await new Promise(resolve => setTimeout(resolve, 2000));
              try {
                const retryInfo = await client.getClusterInfo();
                recoveries++;
                return retryInfo;
              } catch (retryError) {
                persistentFailures++;
                throw retryError;
              }
            }
          },
        ];

        const results = await Promise.allSettled(recoveryTests.map(test => test()));

        const endTime = Date.now();
        const duration = endTime - startTime;
        const recoveryRate = (recoveries / connectionTests) * 100;

        networkMetrics.push({
          test: 'network_recovery',
          latency: duration / connectionTests,
          timeouts: persistentFailures,
          retries: recoveries,
        });

        expect(recoveryRate).toBeGreaterThan(50); // At least 50% recovery rate
        logger.general.info(
          `‚úÖ Network recovery: ${recoveryRate.toFixed(1)}% recovery rate, ${persistentFailures} persistent failures`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Network recovery test encountered issues');

        networkMetrics.push({
          test: 'network_recovery',
          latency: Date.now() - startTime,
          timeouts: persistentFailures || 1,
          retries: recoveries || 0,
        });
      }
    });

    test('Rate limiting and backoff strategies', async () => {
      logger.general.info('üö¶ Testing rate limiting and backoff...');

      const startTime = Date.now();
      let rateLimitHits = 0;
      let backoffAttempts = 0;
      let successfulAfterBackoff = 0;

      try {
        // Rapid-fire requests to trigger rate limiting
        const rapidRequests = 30;
        const baseDelay = 100; // Start with 100ms

        for (let i = 0; i < rapidRequests; i++) {
          try {
            await client.getClusterInfo();
          } catch (error) {
            if (
              (error.message && error.message.includes('rate')) ||
              error.message.includes('limit')
            ) {
              rateLimitHits++;

              // Implement exponential backoff
              backoffAttempts++;
              const backoffDelay = baseDelay * Math.pow(2, Math.min(backoffAttempts, 5));
              await new Promise(resolve => setTimeout(resolve, backoffDelay));

              // Retry after backoff
              try {
                await client.getClusterInfo();
                successfulAfterBackoff++;
              } catch (retryError) {
                // Continue to next iteration
              }
            }
          }

          // Small delay between requests
          await new Promise(resolve => setTimeout(resolve, 50));
        }

        const endTime = Date.now();
        const duration = endTime - startTime;
        const rateLimitRate = (rateLimitHits / rapidRequests) * 100;
        const backoffSuccessRate =
          backoffAttempts > 0 ? (successfulAfterBackoff / backoffAttempts) * 100 : 0;

        networkMetrics.push({
          test: 'rate_limiting_backoff',
          latency: duration / rapidRequests,
          timeouts: rateLimitHits,
          retries: backoffAttempts,
        });

        // Rate limiting is expected, so we test recovery
        if (rateLimitHits > 0) {
          expect(backoffSuccessRate).toBeGreaterThan(30); // At least 30% recovery after backoff
        }

        logger.general.info(
          `‚úÖ Rate limiting test: ${rateLimitRate.toFixed(1)}% rate limited, ${backoffSuccessRate.toFixed(1)}% backoff recovery`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Rate limiting test encountered issues');

        networkMetrics.push({
          test: 'rate_limiting_backoff',
          latency: Date.now() - startTime,
          timeouts: rateLimitHits || 0,
          retries: backoffAttempts || 0,
        });
      }
    });
  });

  describe('Blockchain Transaction Throughput', () => {
    test('Transaction batching performance', async () => {
      logger.general.info('‚õìÔ∏è Testing transaction batching...');

      if (testUsers.length < 2) {
        logger.general.warn('‚ö†Ô∏è Insufficient test users for transaction batching');
        return;
      }

      const startTime = Date.now();
      let batchedTransactions = 0;
      let individualTransactions = 0;
      let batchErrors = 0;

      try {
        // Test individual transactions
        const individualStart = Date.now();
        const individualPromises = testUsers
          .slice(0, 3)
          .map(user => client.getBalance(user.address));

        const individualResults = await Promise.allSettled(individualPromises);
        individualTransactions = individualResults.filter(r => r.status === 'fulfilled').length;
        const individualDuration = Date.now() - individualStart;

        // Test batched operations (simulated)
        const batchStart = Date.now();
        const batchOperations = [
          client.getClusterInfo(),
          client.isConnected(),
          ...testUsers.slice(0, 5).map(user => client.getBalance(user.address)),
        ];

        const batchResults = await Promise.allSettled(batchOperations);
        batchedTransactions = batchResults.filter(r => r.status === 'fulfilled').length;
        batchErrors = batchResults.filter(r => r.status === 'rejected').length;
        const batchDuration = Date.now() - batchStart;

        const individualThroughput = individualTransactions / (individualDuration / 1000);
        const batchThroughput = batchedTransactions / (batchDuration / 1000);

        performanceMetrics.push({
          test: 'transaction_batching',
          duration: Date.now() - startTime,
          throughput: Math.max(individualThroughput, batchThroughput),
          success: individualTransactions + batchedTransactions,
          errors: batchErrors,
        });

        expect(batchThroughput).toBeGreaterThanOrEqual(individualThroughput * 0.8); // Batching should be at least 80% as efficient

        logger.general.info(
          `‚úÖ Transaction batching: Individual ${individualThroughput.toFixed(2)} tx/s, Batch ${batchThroughput.toFixed(2)} tx/s`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Transaction batching test encountered issues');

        performanceMetrics.push({
          test: 'transaction_batching',
          duration: Date.now() - startTime,
          throughput: 0,
          success: batchedTransactions + individualTransactions,
          errors: batchErrors + 1,
        });
      }
    });

    test('Blockchain confirmation speed', async () => {
      logger.general.info('‚è±Ô∏è Testing blockchain confirmation speeds...');

      if (testUsers.length === 0) {
        logger.general.warn('‚ö†Ô∏è No test users for confirmation speed testing');
        return;
      }

      const confirmationTests = [];
      const testOperations = [
        () => client.getBalance(testUsers[0].address),
        () => client.getClusterInfo(),
        () => client.isConnected(),
      ];

      try {
        for (const operation of testOperations) {
          const operationStart = Date.now();

          try {
            await operation();
            const operationDuration = Date.now() - operationStart;
            confirmationTests.push({
              operation: operation.name || 'unknown',
              duration: operationDuration,
              success: true,
            });
          } catch (error) {
            const operationDuration = Date.now() - operationStart;
            confirmationTests.push({
              operation: operation.name || 'unknown',
              duration: operationDuration,
              success: false,
            });
          }
        }

        const avgConfirmationTime =
          confirmationTests.reduce((sum, test) => sum + test.duration, 0) /
          confirmationTests.length;
        const successfulConfirmations = confirmationTests.filter(test => test.success).length;

        networkMetrics.push({
          test: 'confirmation_speed',
          latency: avgConfirmationTime,
          timeouts: confirmationTests.length - successfulConfirmations,
          retries: 0,
        });

        expect(avgConfirmationTime).toBeLessThan(10000); // Less than 10 seconds average
        logger.general.info(
          `‚úÖ Confirmation speed: ${avgConfirmationTime.toFixed(0)}ms average, ${successfulConfirmations}/${confirmationTests.length} successful`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Confirmation speed test encountered issues');

        networkMetrics.push({
          test: 'confirmation_speed',
          latency: 5000, // Default high latency
          timeouts: 1,
          retries: 0,
        });
      }
    });
  });

  describe('Error Recovery and Graceful Degradation', () => {
    test('Graceful degradation under load', async () => {
      logger.general.info('üîÑ Testing graceful degradation...');

      const startTime = Date.now();
      let degradationLevels = 0;
      let maintainedFunctionality = 0;
      let completeFails = 0;

      try {
        // Simulate increasing load and measure degradation
        const loadLevels = [
          { name: 'light', operations: 5 },
          { name: 'moderate', operations: 10 },
          { name: 'heavy', operations: 15 },
        ];

        for (const level of loadLevels) {
          const levelStart = Date.now();
          const operations = [];

          // Create operations for this load level
          for (let i = 0; i < level.operations; i++) {
            operations.push(client.isConnected());
            if (testUsers.length > 0) {
              operations.push(client.getBalance(testUsers[i % testUsers.length].address));
            }
          }

          const results = await Promise.allSettled(operations);
          const successful = results.filter(r => r.status === 'fulfilled').length;
          const successRate = successful / operations.length;

          if (successRate >= 0.8) {
            maintainedFunctionality++;
          } else if (successRate >= 0.4) {
            degradationLevels++;
          } else {
            completeFails++;
          }

          const levelDuration = Date.now() - levelStart;
          logger.general.info(
            `   ${level.name} load: ${(successRate * 100).toFixed(1)}% success in ${levelDuration}ms`,
          );
        }

        const endTime = Date.now();
        const duration = endTime - startTime;

        performanceMetrics.push({
          test: 'graceful_degradation',
          duration,
          throughput: maintainedFunctionality + degradationLevels * 0.5,
          success: maintainedFunctionality + degradationLevels,
          errors: completeFails,
        });

        // System should maintain some functionality even under load
        expect(maintainedFunctionality + degradationLevels).toBeGreaterThan(0);
        logger.general.info(
          `‚úÖ Graceful degradation: ${maintainedFunctionality} maintained, ${degradationLevels} degraded, ${completeFails} failed`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Graceful degradation test encountered issues');

        performanceMetrics.push({
          test: 'graceful_degradation',
          duration: Date.now() - startTime,
          throughput: 0,
          success: 0,
          errors: 1,
        });
      }
    });

    test('Error recovery and system resilience', async () => {
      logger.general.info('üõ°Ô∏è Testing error recovery and resilience...');

      const startTime = Date.now();
      let recoveryAttempts = 0;
      let successfulRecoveries = 0;
      let permanentFailures = 0;

      try {
        // Simulate various error conditions and recovery attempts
        const errorScenarios = [
          {
            name: 'connection_test',
            operation: () => client.isConnected(),
            retryable: true,
          },
          {
            name: 'balance_check',
            operation: () =>
              testUsers.length > 0 ? client.getBalance(testUsers[0].address) : Promise.resolve(0),
            retryable: true,
          },
          {
            name: 'cluster_info',
            operation: () => client.getClusterInfo(),
            retryable: true,
          },
        ];

        for (const scenario of errorScenarios) {
          let attempts = 0;
          let recovered = false;
          const maxAttempts = 3;

          while (attempts < maxAttempts && !recovered) {
            attempts++;
            recoveryAttempts++;

            try {
              await scenario.operation();
              recovered = true;
              successfulRecoveries++;
            } catch (error) {
              if (attempts < maxAttempts && scenario.retryable) {
                // Reduced exponential backoff to fit within timeout
                const delay = Math.pow(2, attempts) * 100; // Reduced from 500 to 100
                await new Promise(resolve => setTimeout(resolve, delay));
              }
            }
          }

          if (!recovered) {
            permanentFailures++;
          }
        }

        const endTime = Date.now();
        const duration = endTime - startTime;
        const recoveryRate = (successfulRecoveries / recoveryAttempts) * 100;

        performanceMetrics.push({
          test: 'error_recovery',
          duration,
          throughput: successfulRecoveries / (duration / 1000),
          success: successfulRecoveries,
          errors: permanentFailures,
        });

        // Should recover from at least some errors
        expect(recoveryRate).toBeGreaterThan(30); // At least 30% recovery rate

        logger.general.info(
          `‚úÖ Error recovery: ${recoveryRate.toFixed(1)}% recovery rate, ${permanentFailures} permanent failures`,
        );
      } catch (error) {
        logger.general.warn('‚ö†Ô∏è Error recovery test encountered issues');

        performanceMetrics.push({
          test: 'error_recovery',
          duration: Date.now() - startTime,
          throughput: 0,
          success: successfulRecoveries,
          errors: permanentFailures + 1,
        });
      }
    });
  });
});
